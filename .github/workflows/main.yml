name: Deploy to Databricks 

on: 
  push: 
    branches: 
      - main 

jobs: 
  deploy_dev: 
    runs-on: ubuntu-latest 
    
    steps: 
    - name: Checkout code 
      uses: actions/checkout@v2 

    - name: Install Databricks CLI and dependencies 
      run: | 
        pip install databricks-cli 
        pip install urllib3==1.26.6 chardet==3.0.4 

    - name: Configure Databricks CLI 
      env: 
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }} 
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }} 
      run: | 
        cat <<EOF | databricks configure --token 
        $DATABRICKS_HOST 
        $DATABRICKS_TOKEN 
        EOF 

    - name: Validate Databricks CLI Configuration 
      run: databricks workspace list 

    - name: Sync to Databricks 
      run: databricks workspace import_dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/release 

  deploy_prod: 
    runs-on: ubuntu-latest 
    needs: deploy_dev 

    steps: 
    - name: Checkout code 
      uses: actions/checkout@v2 

    - name: Install Databricks CLI and dependencies 
      run: | 
        pip install databricks-cli 
        pip install urllib3==1.26.6 chardet==3.0.4 

    - name: Configure Databricks CLI 
      env: 
        PROD_DATABRICKS_HOST: ${{ secrets.PROD_DATABRICKS_HOST }} 
        PROD_DATABRICKS_TOKEN: ${{ secrets.PROD_DATABRICKS_TOKEN }} 
      run: | 
        cat <<EOF | databricks configure --token 
        $PROD_DATABRICKS_HOST 
        $PROD_DATABRICKS_TOKEN 
        EOF 

    - name: Validate Databricks CLI Configuration for Production 
      run: databricks workspace list 

    - name: Sync to Databricks Production 
      run: databricks workspace import_dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release


    - name: Rename tables in production
      run: |
        # List tables in the production release directory
        TABLES=$(databricks workspace ls /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release --output JSON | jq -r '.objects[].path')
        
        # Loop through each table and rename it with prod_ prefix
        for TABLE in $TABLES; do
          echo "TABLE"

          # TEMP_DIR="/tmp/databricks_temp"
          # mkdir -p $TEMP_DIR
          
          # # Export table to a temporary location
          # databricks workspace export --format DBC $TABLE $TEMP_DIR/${TABLE##*/}.dbc
          
          # # Import table with new name
          # databricks workspace import --format DBC --overwrite $TEMP_DIR/${TABLE##*/}.dbc /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$PROD_TABLE_NAME
          
          # # Remove the old table
          # databricks workspace delete $TABLE
        done
