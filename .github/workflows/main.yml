name: Deploy to Databricks

on:
  push:
    branches:
      - main

jobs:
  deploy_dev:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Install Databricks CLI and jq
      run: |
        pip install databricks-cli
        pip install urllib3==1.26.6 chardet==3.0.4
        sudo apt-get install -y jq

    - name: Configure Databricks CLI for Development
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        mkdir -p ~/.databricks
        echo "[DEFAULT]" > ~/.databricks/config
        echo "host = $DATABRICKS_HOST" >> ~/.databricks/config
        echo "token = $DATABRICKS_TOKEN" >> ~/.databricks/config

    - name: Validate Databricks CLI Configuration
      run: databricks workspace ls /

    - name: Sync to Databricks
      run: databricks workspace import-dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/release

  deploy_prod:
    runs-on: ubuntu-latest
    needs: deploy_dev

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Install Databricks CLI and jq
      run: |
        pip install databricks-cli
        pip install urllib3==1.26.6 chardet==3.0.4
        sudo apt-get install -y jq

    - name: Configure Databricks CLI for Production
      env:
        DATABRICKS_HOST: ${{ secrets.PROD_DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.PROD_DATABRICKS_TOKEN }}
      run: |
        mkdir -p ~/.databricks
        echo "[DEFAULT]" > ~/.databricks/config
        echo "host = $DATABRICKS_HOST" >> ~/.databricks/config
        echo "token = $DATABRICKS_TOKEN" >> ~/.databricks/config

    - name: Validate Databricks CLI Configuration for Production
      run: databricks workspace ls /

    - name: Sync to Databricks Production
      run: databricks workspace import-dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release

    - name: Rename tables in production
      run: |
        # List tables in the production release directory
        TABLES=$(databricks workspace ls /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release --output JSON | jq -r '.objects[].path')
        
        # Loop through each table and rename it with prod_ prefix
        for TABLE in $TABLES; do
          PROD_TABLE_NAME=prod_${TABLE##*/}
          # Export table to a temporary location
          databricks workspace export --format DBC /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$TABLE /tmp/${TABLE##*/}.dbc
          # Import table with new name
          databricks workspace import --format DBC --overwrite /tmp/${TABLE##*/}.dbc /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$PROD_TABLE_NAME
          # Remove the old table
          databricks workspace delete /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$TABLE
        done
