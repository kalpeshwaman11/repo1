name: Deploy to Databricks

on:
  push:
    branches:
      - main

jobs:
  deploy_dev:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Install Databricks CLI
      run: pip install databricks-cli

    - name: Configure Databricks CLI
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        mkdir -p ~/.databricks
        cat <<EOF > ~/.databricks/config
        [DEFAULT]
        host = $DATABRICKS_HOST
        token = $DATABRICKS_TOKEN
        EOF

    - name: Validate Databricks CLI Configuration
      run: databricks workspace ls /

    - name: Sync to Databricks
      run: databricks workspace import-dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/release

  deploy_prod:
    runs-on: ubuntu-latest
    needs: deploy_dev

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Install Databricks CLI
      run: pip install databricks-cli

    - name: Configure Databricks CLI
      env:
        DATABRICKS_HOST: ${{ secrets.PROD_DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.PROD_DATABRICKS_TOKEN }}
      run: |
        mkdir -p ~/.databricks
        cat <<EOF > ~/.databricks/config
        [DEFAULT]
        host = $DATABRICKS_HOST
        token = $DATABRICKS_TOKEN
        EOF

    - name: Validate Databricks CLI Configuration for Production
      run: databricks workspace ls /

    - name: Sync to Databricks Production
      run: databricks workspace import-dir --overwrite release /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release

    - name: Rename tables in production
      env:
        DATABRICKS_HOST: ${{ secrets.PROD_DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.PROD_DATABRICKS_TOKEN }}
      run: |
        # List tables in the production release directory
        TABLES=$(databricks workspace ls /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release --output JSON | jq -r '.objects[].path')
        
        # Loop through each table and rename it with prod_ prefix
        for TABLE in $TABLES; do
          PROD_TABLE_NAME=prod_${TABLE##*/}
          # Export table to a temporary location
          databricks workspace export --format DBC /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$TABLE /tmp/$TABLE.dbc
          # Import table with new name
          databricks workspace import --format DBC --overwrite /tmp/$TABLE.dbc /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$PROD_TABLE_NAME
          # Remove the old table
          databricks workspace delete /Workspace/Users/kalpesh.azure.subscription@gmail.com/prod_release/$TABLE
        done
